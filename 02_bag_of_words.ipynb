{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW) Representation\n",
    "\n",
    "The **Bag of Words (BoW)** model is one of the most fundamental methods used to represent text data in numerical form. It provides a way to convert a collection of text documents into a set of features that can be used in machine learning models. BoW is simple yet effective for many natural language processing (NLP) tasks, such as classification, clustering, and sentiment analysis.\n",
    "\n",
    "##### What is Bag of Words?\n",
    "\n",
    "In the **Bag of Words** model, each document is represented by a vector of word frequencies. Essentially, BoW disregards grammar and word order, focusing only on whether known words occur in the document and how often. The model assumes that the occurrence of each word is independent of other words, which simplifies the representation.\n",
    "\n",
    "For example, consider the following two sentences:\n",
    "\n",
    "- \"The cat sat on the mat.\"\n",
    "- \"The dog lay on the mat.\"\n",
    "\n",
    "The vocabulary for these two sentences would be: **[the, cat, sat, on, mat, dog, lay]**. Each sentence is then represented by a frequency vector showing how often each word appears.\n",
    "\n",
    "##### How Bag of Words Works\n",
    "\n",
    "1. **Create Vocabulary**: Construct a list of all unique words that appear across all documents in the dataset. This list is referred to as the vocabulary.\n",
    "2. **Vector Representation**: For each document, create a vector where each element corresponds to a word in the vocabulary. The value in each position indicates how many times the corresponding word appears in that document.\n",
    "\n",
    "For the example above, the frequency vectors would be:\n",
    "\n",
    "- \"The cat sat on the mat\" -> **[2, 1, 1, 1, 1, 0, 0]**\n",
    "- \"The dog lay on the mat\" -> **[2, 0, 0, 1, 1, 1, 1]**\n",
    "\n",
    "##### Advantages and Limitations of Bag of Words\n",
    "\n",
    "**Advantages**:\n",
    "- **Simplicity**: BoW is easy to implement and understand.\n",
    "- **Effectiveness**: Works well for a variety of text classification tasks.\n",
    "\n",
    "**Limitations**:\n",
    "- **Sparsity**: For large vocabularies, the resulting vectors can be very sparse (most elements are zero).\n",
    "- **No Semantic Information**: BoW does not consider word order or semantics, so the context is lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Example of BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Machine learning is a fascinating field\",\n",
    "    \"Data science and machine learning are closely related\",\n",
    "    \"Deep learning is a subfield of machine learning\",\n",
    "    \"Supervised learning involves labeled data\",\n",
    "    \"Unsupervised learning deals with unlabeled data\",\n",
    "    \"Feature engineering is crucial for model performance\",\n",
    "    \"Data preprocessing is an important step in machine learning\",\n",
    "    \"Natural language processing is a key area in AI\",\n",
    "    \"Hyperparameter tuning helps to optimize models\",\n",
    "    \"Model evaluation is necessary for understanding model accuracy\"\n",
    "]\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Alternatively, for larger corpora\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=50)\n",
    "\n",
    "# Fit and transform the documents to create the BoW representation\n",
    "bow_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the BoW matrix to an array and print the vocabulary\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Representation:\\n\", bow_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize Frequency\n",
    "You can visualize the frequency of words in the Bag of Words model using bar plots or word clouds. Visualizing word frequency can provide valuable insights into the text data, allowing you to see which words are most prominent in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the vocabulary and word frequencies (we created the vectorizer earlier)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "frequencies = np.array(bow_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "# Sort the vocabulary and frequencies by frequency in descending order\n",
    "sorted_indices = np.argsort(-frequencies)\n",
    "sorted_vocabulary = vocabulary[sorted_indices]\n",
    "sorted_frequencies = frequencies[sorted_indices]\n",
    "\n",
    "# Plot the word frequencies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(sorted_vocabulary, sorted_frequencies)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Word Frequencies in Bag of Words')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize Wordcloud\n",
    "Another way to visualize word frequencies is by using a word cloud, which can provide an engaging representation of the most frequent words in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(zip(vocabulary, frequencies)))\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Working with a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('movies_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=50)\n",
    "\n",
    "# Fit and transform the documents to create the BoW representation\n",
    "bow_matrix = vectorizer.fit_transform(df['Plot'])\n",
    "\n",
    "# Create a DataFrame for the BoW representation\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=df.index)\n",
    "\n",
    "# Display the vocabulary and BoW DataFrame\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"\\nBag of Words DataFrame:\")\n",
    "print(bow_df)\n",
    "\n",
    "# Merge the BoW DataFrame with the original DataFrame for a complete view\n",
    "df = pd.concat([df, bow_df], axis=1)\n",
    "print(\"\\nOriginal DataFrame with BoW Representation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Visualize Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the vocabulary and word frequencies (we created the vectorizer earlier)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "frequencies = np.array(bow_matrix.sum(axis=0)).flatten()\n",
    "\n",
    "# Sort the vocabulary and frequencies by frequency in descending order\n",
    "sorted_indices = np.argsort(-frequencies)\n",
    "sorted_vocabulary = vocabulary[sorted_indices]\n",
    "sorted_frequencies = frequencies[sorted_indices]\n",
    "\n",
    "# Plot the word frequencies\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(sorted_vocabulary, sorted_frequencies)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Word Frequencies in Bag of Words')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Visualize Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(dict(zip(vocabulary, frequencies)))\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Translate to the Case\n",
    "Go to the case and perform BoW on the news articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
